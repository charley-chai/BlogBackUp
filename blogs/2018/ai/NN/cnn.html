<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <script src="/scripts/src/jquery.min.js"></script>
    <link rel="shortcut icon" type="image/x-icon" href="/images/logo.png" />
    <title>CNNs</title>
    <link rel="stylesheet" href="/styles/temp.css">
    <link rel="stylesheet" href="/styles/blogs.css">
    <link rel="stylesheet" href="/styles/article_blog.css">
    <link rel="stylesheet" href="/styles/timeline.css">
    <link rel="stylesheet" href="/styles/prism.css">
    <meta name="keywords" content="NN ML CNN tensorflow keras python 神经网络 机器学习 历史 CharleyChai 博客 柴磊">
    <meta name="description" content="">
    <meta name="author" content="Charley Chai">
    <meta property="og:image" content="/images/logo.png">
    <meta property="og:description" content="NN ML CNN tensorflow keras python 神经网络 机器学习 历史 CharleyChai 博客 柴磊">
    <meta property="og:title" content="CNNs">
    <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
            extensions: ["tex2jax.js"],
            jax: ["input/TeX","output/HTML-CSS"],
            tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}
          });
        </script>
    <script type="text/javascript" src="/scripts/src/MathJax/MathJax.js"></script>
</head>

<body>
    <header>
        <div class="container">
            <nav id="xxxx">
                <ul>
                    <li class="frim" id="expand">
                        <p>
                            <img src="/images/expand.svg" class="logo">
                        </p>
                    </li>
                    <li class="frim">
                        <a href="/">
                            <img src="/images/logo.svg" class="logo" id="logo">
                        </a>
                    </li>
                    <li class="shift"><a href="/">Home</a></li>
                    <li class="shift"><a href="/blogs" class="hoster">Blogs</a></li>
                    <li class="shift"><a href="/notes">Courses</a></li>
                    <li class="shift"><a href="/projects">Projects</a></li>
                    <li class="shift"><a href="/hobbies">Hobbies</a></li>
                    <li class="frim" id="search">
                        <p>
                            <img src="/images/search.svg" class="logo">
                        </p>
                    </li>
                </ul>
            </nav>
        </div>
    </header>

    <div id="placeholder"></div>

    <div id="sub_nav">
        <ul>
            <li><a href="/">Home</a></li>
            <hr color="#555" size=0.5>
            <li><a href="/blogs">Blogs</a></li>
            <hr color="#555" size=0.5>
            <li><a href="/notes">Courses</a></li>
            <hr color="#555" size=0.5>
            <li><a href="/projects">Projects</a></li>
            <hr color="#555" size=0.5>
            <li><a href="/hobbies">Hobbies</a></li>
        </ul>
    </div>

    <div id="top" class="content">
        <nav id="class_nav">
            <ul>
                <li id="bloghost" class="frim"><a href="/blogs">Blogs</a></li>
                <li class="shift"><a href="/blogs/classify/advanced.html">Advanced</a></li>
                <li class="shift"><a href="/blogs/classify/network.html">Network</a></li>
                <li class="shift"><a href="/blogs/classify/ai.html" class="host">AI</a></li>
                <li class="shift"><a href="/blogs/classify/ui.html">UI/UX</a></li>
                <li class="shift"><a href="/blogs/classify/tools.html">Tools</a></li>
                <li class="frim" id="expandmore"><a href="#">
                        <svg id="next" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
                            <path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z" />
                            <path d="M0 0h24v24H0z" fill="none" />
                        </svg>
                        <svg id="next1" class="hidden" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                            <defs>
                                <style>
                                    .cls-1 {
                                        fill: none;
                                    }
                                </style>
                            </defs>
                            <g id="baseline-navigate_next-24px" transform="translate(24) rotate(90)">
                                <path id="Path_1" data-name="Path 1" d="M10,6,8.59,7.41,13.17,12,8.59,16.59,10,18l6-6Z" />
                                <path id="Path_2" data-name="Path 2" class="cls-1" d="M0,0H24V24H0Z" />
                            </g>
                        </svg>
                    </a></li>
            </ul>
        </nav>

        <div id="class_sub_nav">
            <ul>
                <li><a href="/blogs">Blogs</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/advanced.html">Advanced</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/network.html">Network</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/ai.html">AI</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/ui.html">UI/UX</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/tools.html" class="host">Tools</a></li>
            </ul>
        </div>

        <main>
            <section class="section_content">
                <div id="blog_head">
                    <div class="blog_tag purple">AI</div>
                    <h1 class="blog_title">CNN简史</h1>
                    <div class="blog_time">OCT 02, 2018</div>
                    <hr />
                </div>
                <img src="/images/blogs/2018/cnntop.png" class="blog_image">

                <div class="blog_content">
                    <p>在这篇文章中，主要来介绍一下CNN的发展历史，在稍后的文章中将会展开来叙说这些一次又一次带给我们惊喜的模型。</p>

                    <div class="timeline">
                    
                        <h4 class="timetag">1962</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-1,
                                            .cls-4 {
                                                fill: none;
                                            }
                    
                                            .cls-1 {
                                                stroke: #f23030;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-2 {
                                                fill: #f23030;
                                            }
                    
                                            .cls-3 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-1" transform="translate(1056 251)">
                                            <circle class="cls-3" cx="25" cy="25" r="25" />
                                            <circle class="cls-4" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-2" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>感受野的提出</h4>
                            <p class="timeintro top-to-bottom"><br />
                                <i>Hubel</i>和<i>Wiesel</i>通过对猫大脑中视觉皮层的研究，他们在论文<i><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1359523/">Receptive fields, binocular interaction and functional architecture in the cat's visual cortex</a></i>中提出了<b>感受野</b>（Receptive fields）的概念，即每个神经元不会对整个图像作出反应，它们仅仅处理某个有限的区域。由此开启了人类对就视觉的科学性研究。
                                <br><br>
                                <img src="/images/blogs/2018/cnn_receptivefield.png" width="50%" style="margin: 0 25%">
                                <br><br>
                                他们在研究中发现当他们切换幻灯片的时候，猫视觉皮层的神经元被激活了；经过深入研究，他们发现视觉皮层的神经元是一列一列组织起来的，而每一列
                                的神经元仅对某一种特定的“形状”（可以理解为我们眼睛捕捉到的简单线条组合）产生兴奋。并且，他们由此获得1981年诺贝尔生理学及医学奖。
                                <br><br>
                                <img src="/images/blogs/2018/cnn_cat.png" width="50%" style="margin: 0 25%">
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>
                    
                    <div class="timeline">
                    
                        <h4 class="timetag">1980</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-11,
                                            .cls-14 {
                                                fill: none;
                                            }
                    
                                            .cls-11 {
                                                stroke: #ffb134;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-12 {
                                                fill: #ffb134;
                                            }
                    
                                            .cls-13 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-11" transform="translate(1056 251)">
                                            <circle class="cls-13" cx="25" cy="25" r="25" />
                                            <circle class="cls-14" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-12" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>神经认知机的提出</h4>
                            <p class="timeintro top-to-bottom1"><br />
                                受到<i>Hubel</i>等人研究成果的启发，日本科学家<i>福岛邦彦</i>于1980年发表论文<i><a href="https://link.springer.com/article/10.1007%2FBF00344251">Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position</a></i>，提出了<b>神经认知机</b>（Neocognitron）的概念。
                                <br><br>
                                <img src="/images/blogs/2018/cnn_neocognnitron.jpg" width="60%" style="margin: 0 20%">
                                <br><br>
                                上图为神经感知机的结构示意图，其结构从简单细胞到超复杂细胞与生物结构一一对应，将脑神经用计算机进行模拟；同时这里使用很多现代CNN的结构，如：过滤器，ReLu激活函数，用平均池化层来下采样等。但是改结构使用基于WTA（Winner Take All）的无监督学习，缺乏实用性。
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>

                    <div class="timeline">
                    
                        <h4 class="timetag">1998</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-21,
                                            .cls-24 {
                                                fill: none;
                                            }
                    
                                            .cls-21 {
                                                stroke: #FAEE5D;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-22 {
                                                fill: #FAEE5D;
                                            }
                    
                                            .cls-23 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-21" transform="translate(1056 251)">
                                            <circle class="cls-23" cx="25" cy="25" r="25" />
                                            <circle class="cls-24" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-22" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>LeNet-5 $\star$</h4>
                            <p class="timeintro top-to-bottom2"><br>
                                <i>Yann LeCun</i>在论文<i><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">Gradient-Based Learning Applied to Document Recognition</a></i>中提出了<b>LeNet-5</b>，值得一提的是当时美国的各大银行已经开始使用该网络来识别支票上的手写数字。
                                <br><br>
                                <img src="/images/blogs/2018/cnn_lenet5.png" width="100%">
                                <br><br>
                                LeNet-5共有7层：输入是 $32 \times 32$ 的图像；<br>
                                <b>$C1$层</b>是一个卷积（Convolution）层，使用 $5 \times 5$ 的卷积核，得到6个 $28 \times 28$ 的特征图；
                                <br> <b>$S2$层</b>是一个下采样（Subsampling）层，对每个特征图进行 $2 \times 2 $ 的下采样，得到6个 $14 \times 14$ 的特征图；
                                <br> <b>$C3$层</b>也是一个卷积层，使用16个 $5 \times 5$ 的卷积核，得到16个 $10 \times 10$ 的特征图；
                                <br> <b>$S4$层</b>是一个下采样层，对每个特征图进行$2 \times 2 $ 的下采样，得到16个 $5 \times 5$ 的特征图；
                                <br> <b>$C5$层</b>是一个卷积层，使用 $5 \times 5$ 的卷积核，得到120个 $1 \times 1$ 的特征图；
                                <br> <b>$F6$层</b>是一个全连接（Full Connection）层，有84个神经元；
                                <br> <b>输出层</b>是一个RBF（Radial Basis Function）层，输出是一个长度为10的向量，代表 $0-9$。
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>

                    <div class="timeline">
                    
                        <h4 class="timetag">2012</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-31,
                                            .cls-34 {
                                                fill: none;
                                            }
                    
                                            .cls-31 {
                                                stroke: #25DD73;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-32 {
                                                fill: #25DD73;
                                            }
                    
                                            .cls-33 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-31" transform="translate(1056 251)">
                                            <circle class="cls-33" cx="25" cy="25" r="25" />
                                            <circle class="cls-34" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-32" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>AlexNet横空出世 $\star$</h4>
                            <p class="timeintro top-to-bottom3"><br>
                                在ImageNet2012的图片分类任务上，<i>Alex Krizhevsky</i>设计的<b>深度卷积神经网络</b>以Top5错误率（给定一张图，其标签不在模型认为的最有可能的5个结果中的几率）15.4%获得第一，而采用SVM的第二名的成绩则是26.2%。
                                <br><br>
                                <img src="/images/blogs/2018/nn_alexnet.jpg" width="100%">
                                <br><br>
                                AlexNet看上去有两股“流”，因为当时GPU的内存较小，而此网络在训练时计算量有很大，所以只能拆开来训练，GPU只在某些层互相通信。
                                <br><br>
                                它由5个卷积层和3个全连接层组成（不包含池化层和LRN层），最后一个全连接层的输出经过一个1000维的Softmax层，从而产生覆盖1000个标签的向量。AlexNet使用ReLU作为激活函数来解决梯度消失问题。其细节可用这张图来表示：
                                <br><br>
                                <img src="/images/blogs/2018/AlexNet_cons.jpg" width="50%" style="margin: 0 25%">
                                <br><br>
                                论文链接：<i><a href="https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf">ImageNet Classification with Deep Convolutional Neural Network</a></i>
                                <br><br><br> </p>
                        </article>
                    
                    </div>

                    <div class="timeline">
                    
                        <h4 class="timetag">2013</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-41,
                                            .cls-44 {
                                                fill: none;
                                            }
                    
                                            .cls-41 {
                                                stroke: #30A4F8;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-42 {
                                                fill: #30A4F8;
                                            }
                    
                                            .cls-43 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-41" transform="translate(1056 251)">
                                            <circle class="cls-43" cx="25" cy="25" r="25" />
                                            <circle class="cls-44" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-42" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>ZFNet：更好的理解CNN</h4>
                            <p class="timeintro top-to-bottom4"><br>
                                <i>Matthew Zeiler</i>和<i>Rob Fergus</i>在AlexNet的基础上进行优化，从而设计出了ZF Net，其在ILSVRC 2013上的战绩是11.2%。值得指出的是，AlexNet使用了1500万张图片进行训练，而ZF Net只用了130万张。
                                <br><br>
                                <img src="/images/blogs/2018/zfnet_cons.png" width="100%">
                                <br><br>
                                在其论文<i><a href="https://arxiv.org/abs/1311.2901">Visualizing and Understanding Convolutional Networks</a></i>中，它们提出了两个新问题：为何CNN如此有效，如何改进CNN。同时作者给出了一个<b>Deconvnet</b>，用来可视化以展示CNN究竟看到了什么特征。这些工作对于理解CNN运作机制，提高CNN的性能做出了巨大贡献。
                                <br><br>
                                <img src="/images/blogs/2018/deconv.png" width="100%">
                                <br><br><br> 
                            </p>
                        </article>
                    
                    </div>

                    <div class="timeline">
                    
                        <h4 class="timetag">2014</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-51,
                                            .cls-54 {
                                                fill: none;
                                            }
                    
                                            .cls-51 {
                                                stroke: #08FDE1;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-52 {
                                                fill: #08FDE1;
                                            }
                    
                                            .cls-53 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-51" transform="translate(1056 251)">
                                            <circle class="cls-53" cx="25" cy="25" r="25" />
                                            <circle class="cls-54" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-52" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>VGGNet</h4>
                            <p class="timeintro top-to-bottom5"><br>
                                牛津大学<i>Visual Geometry Group</i>和<i>DeepMind</i>共同设计了VGGNet，通过反复堆叠 $3 \times 3$ 的小型卷积核和 $2 \times 2$ 的最大池化层构成了一个深度19层的CNN。
                                VGGNet在ILSVRC 2014中获得分类项目的第二，定位项目的第一。其拓展性和泛化能力都很强，其训练好后的模型已<a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/">开源</a>，可以用来在特定任务上进行再训练，因而被广泛应用。
                                <br><br>
                                <img src="/images/blogs/2018/VGGNet_cons.png" width="100%">
                                <br><br>   
                                VGGNet有5段卷积，每一段内有2～3个卷积层，每一段的末尾用一个最大池化层来缩小图片尺寸。每一段内的卷积核数量一样，越往后的段的卷积核数量越多。VGGNet充分说明，一个足够“深”的CNN，真的很有用。                          
                                <br><br>
                                论文链接：<i><a href="https://arxiv.org/pdf/1409.1556.pdf">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></i>
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>

                    <div class="timeline">
                    
                        <h4 class="timetag">2014</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-61,
                                            .cls-64 {
                                                fill: none;
                                            }
                    
                                            .cls-61 {
                                                stroke: #6630F8;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-62 {
                                                fill: #6630F8;
                                            }
                    
                                            .cls-63 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-61" transform="translate(1056 251)">
                                            <circle class="cls-63" cx="25" cy="25" r="25" />
                                            <circle class="cls-64" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-62" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>GoogLeNet</h4>
                            <p class="timeintro top-to-bottom6"><br />
                                GoogLeNet和VGG是ILSVRC 2014的双雄，在图像分类中GoogLeNet获得了第一名、VGG获得了第二名。这两者的共同之处就是都很“深”。GoogLeNet在网络结构上做了大胆的尝试，它可以说是第一个真正不使用通用方法的卷积神经网络架构。
                                GoogLeNet在设计时重点考虑了内存和能量消耗，它虽然有22层，但是比起AlexNet和VGG却要小很多，它有500万个参数，而AlexNet的参数是GoogleNet的12倍，VGGNet参数又是AlexNet的3倍。
                                <br><br>
                                <img src="/images/blogs/2018/GoogLeNet.png" width="100%">
                                <br><br>
                                GoogLeNet的结构跟以往的CNN模型有很大不同，它不再是简单地按顺序进行计算，而将一些计算设计为同时进行，从上面的图中我们就可以窥见一斑。同时我们可以很轻易地观察到GoogLeNet里边重复出现的一个结构（如下图所示，称为Inception模型）。
                                <br><br>
                                <img src="/images/blogs/2018/inception.png" width="50%" style="margin: 0 25%">
                                <br><br>
                                在整个GoogLeNet架构中，一共使用了9个Inception模型。Inception的设计的初衷就是希望通过一个稀疏网络结构，但是能产生稠密的数据，这个模型由一个网络层中的网络（NIN）、一个中等大小的过滤卷积、一个大型的过滤卷积、一个操作池组成。在一个传统的卷积网络中的每一层中，无非是操作池或卷积操作，而Inception模型能让我们做到的就是并行地执行所有的操作。
                                <br><br>
                                论文链接：<i><a href="https://arxiv.org/abs/1409.4842">Going Deeper with Convolutions</a></i>
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>

                    <div class="timeline">
                    
                        <h4 class="timetag">2015</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-1,
                                            .cls-4 {
                                                fill: none;
                                            }
                    
                                            .cls-1 {
                                                stroke: #f23030;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-2 {
                                                fill: #f23030;
                                            }
                    
                                            .cls-3 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-1" transform="translate(1056 251)">
                                            <circle class="cls-3" cx="25" cy="25" r="25" />
                                            <circle class="cls-4" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-2" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>ResNet</h4>
                            <p class="timeintro top-to-bottomendorange"><br/>
                                微软亚洲研究院的ResNet在ILSVRC 2015上取得了惊人的3.6％的Top5误差率，这已经超过了人类（5%～10%）。ResNet模型的最大特点就是很深，达到了152层，它是残差学习理念的一大创新。下面感受一下它的“深”：
                                <br><br>
                                <img src="/images/blogs/2018/resnet.gif" width="50%" style="margin: 0 25%">
                                <br><br>
                                从前面的叙述中，我们可以发现新的模型在不断加“深”，而越深的网络越难以训练，往往会因为梯度爆炸，梯度消失，梯度弥散等问题而导致网络退化，而ResNet却有效地解决了这些问题，
                                从在上面图中，我们可以看到它的结构中有很多重复的结构，我们把它拿出来仔细看（见下图）：
                                <br><br>
                                <img src="/images/blogs/2018/residualblock.png" width="50%" style="margin: 0 25%">
                                <br><br>
                                上面的结构叫做残差块（Residual Block）。这个模块有三层，两层卷积加上一层ReLu层，此外还有一个线将Input与Addition直接相连。其实，这个小模块得到的是原始输入和期望输出的差值。
                                这样能够保证随着深度的提高，其特征图不会有太难以控制的变化，从而解决了网络退化的问题。
                                <br><br>
                                论文链接：<i><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></i>
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>

                </div>

                <div class="blog_content">
                    好嘞，至此，我们已经基本对CNN以及其发展有了一个较全面的了解，后面会有更多更详细的文章来更深入的探讨这些划时代的CNN模型。
                    <br>
                    尽情享用：
                    <ul class="list">
                        <style>
                            .list > li{
                                list-style: decimal;
                            }
                        </style>
                        <li><i><a href="/blogs/2018/ai/NN/lenet.html">LeNet-5</a></i></li>
                    </ul>
                </div>


                <div class="blog_content">
                    <style>
                        #bloglink {
                            text-align: left;
                        }
                    </style>
                    <p>上一篇：<a href="#">无</a></p>
                    <p>下一篇：<a href="/blogs/2018/ai/NN/history_of_rcnn.html">R-CNN简史</a></p>
                </div>

                <div class="blog_content">
                    <h3>参考：</h3>
                    <ul class="reference">
                        <li>
                            <i><a href="https://my.oschina.net/u/876354/blog/1637819">大话CNN经典模型：GoogLeNet（从Inception v1到v4的演进）</a></i>
                        </li>
                        <li>
                            <i><a href="https://blog.csdn.net/marsjhao/article/details/72955935">深度学习经典卷积神经网络之VGGNet</a></i>
                        </li>
                        <li>
                            <i><a href="https://blog.csdn.net/edogawachia/article/details/79968926">classical CNN models : ZF Net 模型结构详解</a></i>
                        </li>
                        <li>
                            <i><a href="https://blog.csdn.net/marsjhao/article/details/72953256">深度学习经典卷积神经网络之AlexNet</a></i>
                        </li>
                        <li>
                            <i><a href="http://m.sohu.com/n/466820078/?pvid=000115_3w_a">计算机视觉和 CNN 发展十一座里程碑</a></i>
                        </li>
                        <li>
                            <i><a href="https://zhuanlan.zhihu.com/p/39068853">CNN简史-知乎</a></i>
                        </li>
                    </ul>
                </div>

            </section>
        </main>
    </div>

    <div id="contact" class="content">
        <p id="welcome">Welcome to join me to find and create bueautiful stuffs!</p>
        <p id="cvia">Contact me via:</p>
        <div id="mi_logos">
            <img src="/images/facebook.svg" class="logos link">
            <img src="/images/instagram.svg" class="logos link">
            <img src="/images/twitter.svg" class="logos link">
            <img src="/images/wechat.svg" class="logos link">
            <img src="/images/weibo.svg" class="logos link">
        </div>
        <hr />
        <p id="copyright">A project by Charley Chai</p>
    </div>
    <script src="/scripts/temp.js"></script>
    <script src="/scripts/blogs.js"></script>
    <script src="/scripts/src/prism.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
</body>

</html>