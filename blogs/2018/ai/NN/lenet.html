<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <script src="/scripts/src/jquery.min.js"></script>
    <link rel="shortcut icon" type="image/x-icon" href="/images/logo.png" />
    <title>LeNet-5详解与实现</title>
    <link rel="stylesheet" href="/styles/temp.css">
    <link rel="stylesheet" href="/styles/blogs.css">
    <link rel="stylesheet" href="/styles/article_blog.css">
    <link rel="stylesheet" href="/styles/timeline.css">
    <meta name="keywords" content="NN ML CNN LeNet-5 lua torch pytorch python 神经网络 机器学习 历史 CharleyChai 博客 柴磊">
    <meta name="description" content="">
    <meta name="author" content="Charley Chai">
    <meta property="og:image" content="/images/logo.png">
    <meta property="og:description" content="NN ML CNN LeNet-5 lua torch pytorch python 神经网络 机器学习 历史 CharleyChai 博客 柴磊">
    <meta property="og:title" content="LeNet-5详解与实现">
    <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
            extensions: ["tex2jax.js"],
            jax: ["input/TeX","output/HTML-CSS"],
            tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}
          });
        </script>
    <script type="text/javascript" src="/scripts/src/MathJax/MathJax.js"></script>
</head>

<body>
    <header>
        <div class="container">
            <nav id="xxxx">
                <ul>
                    <li class="frim" id="expand">
                        <p>
                            <img src="/images/expand.svg" class="logo">
                        </p>
                    </li>
                    <li class="frim">
                        <a href="/">
                            <img src="/images/logo.svg" class="logo" id="logo">
                        </a>
                    </li>
                    <li class="shift"><a href="/">Home</a></li>
                    <li class="shift"><a href="/blogs" class="hoster">Blogs</a></li>
                    <li class="shift"><a href="/notes">Courses</a></li>
                    <li class="shift"><a href="/projects">Projects</a></li>
                    <li class="shift"><a href="/hobbies">Hobbies</a></li>
                    <li class="frim" id="search">
                        <p>
                            <img src="/images/search.svg" class="logo">
                        </p>
                    </li>
                </ul>
            </nav>
        </div>
    </header>

    <div id="placeholder"></div>

    <div id="sub_nav">
        <ul>
            <li><a href="/">Home</a></li>
            <hr color="#555" size=0.5>
            <li><a href="/blogs">Blogs</a></li>
            <hr color="#555" size=0.5>
            <li><a href="/notes">Courses</a></li>
            <hr color="#555" size=0.5>
            <li><a href="/projects">Projects</a></li>
            <hr color="#555" size=0.5>
            <li><a href="/hobbies">Hobbies</a></li>
        </ul>
    </div>

    <div id="top" class="content">
        <nav id="class_nav">
            <ul>
                <li id="bloghost" class="frim"><a href="/blogs">Blogs</a></li>
                <li class="shift"><a href="/blogs/classify/advanced.html">Advanced</a></li>
                <li class="shift"><a href="/blogs/classify/network.html">Network</a></li>
                <li class="shift"><a href="/blogs/classify/ai.html" class="host">AI</a></li>
                <li class="shift"><a href="/blogs/classify/ui.html">UI/UX</a></li>
                <li class="shift"><a href="/blogs/classify/tools.html">Tools</a></li>
                <li class="frim" id="expandmore"><a href="#">
                        <svg id="next" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
                            <path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z" />
                            <path d="M0 0h24v24H0z" fill="none" />
                        </svg>
                        <svg id="next1" class="hidden" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                            <defs>
                                <style>
                                    .cls-1 {
                                        fill: none;
                                    }
                                </style>
                            </defs>
                            <g id="baseline-navigate_next-24px" transform="translate(24) rotate(90)">
                                <path id="Path_1" data-name="Path 1" d="M10,6,8.59,7.41,13.17,12,8.59,16.59,10,18l6-6Z" />
                                <path id="Path_2" data-name="Path 2" class="cls-1" d="M0,0H24V24H0Z" />
                            </g>
                        </svg>
                    </a></li>
            </ul>
        </nav>

        <div id="class_sub_nav">
            <ul>
                <li><a href="/blogs">Blogs</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/advanced.html">Advanced</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/network.html">Network</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/ai.html">AI</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/ui.html">UI/UX</a></li>
                <hr color="#BBB" size=0.2>
                <li><a href="/blogs/classify/tools.html" class="host">Tools</a></li>
            </ul>
        </div>

        <main>
            <section class="section_content">
                <div id="blog_head">
                    <div class="blog_tag purple">AI</div>
                    <h1 class="blog_title">LeNet-5详解与实现</h1>
                    <div class="blog_time">OCT 07, 2018</div>
                    <hr />
                </div>
                <img src="/images/blogs/2018/cnn_lenet5.png" class="blog_image">

                <div class="blog_content">
                    <p>论文链接：<i><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">Gradient-Based Learning Applied to Document Recognition</a></i></p>
                    <p>⚠️：文章中的部分图片修改自台湾大学<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17.html">李宏毅</a>老师的PPT</p>
                </div>

                <style>
                    h5{
                        color: gray;
                    }
                </style>

                <div class="blog_content">
                    <h3>CNN 的两大法宝</h3>
                    <p>其实在前面对CNN的简介中，我们已经说到，CNN就是到人们对视觉皮质层的研究成果的启发而设计出来的，CNN的精髓正是从视觉皮质层的特点而来的。</p>
                    <h4>#1 局部连接</h4>
                    <p>
                        这里提出一个概念——<b>局部感受野</b>，它由<i>Hubel</i>和<i>Wiesel</i>等人在研究生物视觉时率先提出。所谓局部感受野，也就是说他们发现视觉神经元并不会对眼睛看到的所有图像有反应，而仅仅处理某个有限的区域。
                        这一事实，一定程度上启发了CNN的结构设计。而且，这也符合我们的一般认知：人对外界的认知一般是从局部到全局的，而图像的空间联系也是局部的像素联系较为紧密，而距离较远的像素相关性则较弱。
                    </p>
                    <p>
                        拿图像识别这种任务来说，如果我们使用全连接深度神经网络来做这个事情。例如我们要训练出一个全连接深度神经网络，它可以对1000X1000大小的图像进行识别，那么就仅仅输入层就要又1000000个神经元，相应的我们这个网络的隐含层还要足够的“宽度”和“深度”。
                        可想而知，我们需要多么巨大的参数，这无疑给网络训练速度和预测速度的提升带来巨大的阻碍，而且很容易出现过拟合；同时，我们将二维图像简单地展开成一维图像，已经破坏了原始图像中的一些空间信息。CNN采用局部连接的方法来解决上面的问题。
                    </p>
                    <p>
                        如下图所示，左为全连接，右为局部连接，易见参数极大地减少。
                    </p>
                    <img src="/images/blogs/2018/full_conv.jpg" width="100%">
                    <p>
                        再看下面这张图，采用局部连接可以免除一些因为平移或者旋转带来的干扰。
                    </p>
                    <img src="/images/blogs/2018/cnn_local" width="100%">
                </div>

                <div class="blog_content">
                    <h4>#2 权值共享</h4>
                    <p>
                        但是如果这样之后，其实参数还是有很多的。还以1000X1000的图像为例，如果我们仅仅采用局部连接的方法，假设第一个隐含层的每个神经元只与输入的10X10的像素点连接，那么这样依然有近100X100组参数，而每组参数又有100个，参数还是有很很多的。
                        而所谓参数共享就是让同一个隐含层中的神经元参数都相同，这样的话，其实我们仅仅需要100个参数而已，可以在参考上图。
                    </p>
                    
                </div>


                <div class="blog_content">
                    <h3>卷积操作</h3>
                    <h4>$\star$ 基本操作</h4>
                    <p>
                        卷积操作可以说是CNN的核心了，它也正是得名于此，也正式卷积操作，让CNN得以拥有局部连接和权值共享这两件法宝。至于卷积操作到底是什么样子的呢？先看一个图吧。
                    </p>
                    <img src="/images/blogs/2018/conv_demo.gif" width="70%" style="margin: 0 15%">
                    <p>
                        卷积操作的目的其实就是为了从原始数据中提取出所谓特征。假设说我们有一张6X6黑白图片，其像素信息为：
                        <img src="/images/blogs/2018/cnn_sample_img.png" width="40%" style="margin: 0 30%">
                        <br><br>
                        然后，这里我们有两个3X3的滤波器(Filter)或者称为卷积核(kernel)：
                        <img src="/images/blogs/2018/cnn_filter.png" width="60%" style="margin: 0 20%">
                    </p>
                    <p>
                        所谓卷积操作就是使用这些卷积核，按照上面动图的规则来进行计算，我们就可以得到下面的结果（由圆形组成的矩阵），称之为<b>特征图</b>(Feature Map)：
                        <img src="/images/blogs/2018/cnn_filter_rsl.png" width="70%" style="margin: 0 15%">
                        <br><br>
                        这里的操作称为一次卷积操作：
                        $$ result = \sum_{i = 0, j = 0}^{i = 2, j = 2} selectedPiexl_{ij} \times kernel_{ij} .$$
                    </p>
                    <h4>$\star$ 卷积的作用</h4>
                    <p>
                        那么，卷积操作的意义何在呢？它主要用来提取某种特征。还是回想一下之前介绍过的<i>Hubel</i>等人发现视觉皮质层内的一些视觉神经元它们仅仅对图像中的某一些特征才起反应。
                        而我们的这里的卷积就是在模拟这样一种特性，看下图：
                        <img src="/images/blogs/2018/cnn_filter_use.png" width="70%" style="margin: 0 15%">
                    </p>
                    <p>
                        我们观察这个3X3的卷积核中的数字，可以发现其对角线上的元素的值最大为1，而其他地方为-1，如果我们认为,这个卷积每进行一次卷积操作得到的数值的值越大，表示该卷积越喜欢这一块区域。
                        那么显然我们这个卷积核最喜欢的区域就是：对角线为1其余地方为0的3X3的区域。这次再看上面的图，就很容易理解为什么得到的特征图中用蓝框框住的元素的值是最大的了。
                        我们其实可以看到，一个卷积核他只对图中的某一个特征(斜线，数线，某种特定颜色等等)感兴趣。但是我们如果要对一张图片进行分析时，往往需要综合很多东西，所以我们其实就需要多个卷积核共同工作。
                        就像下面这样：
                    </p>
                    <img src="/images/blogs/2018/cnn_multifilter.png" width="70%" style="margin: 0 15%">
                    <p>
                        而CNN的一个主要的任务就是从训练集中“学习出”这些卷积核，来让自己有从图中提取合适的特征的能力。例如，经过训练之后，有些卷积核可以提取出图中的边缘信息，有的可以提取出图中的水平方向的线条，再比如在一些彩色图像中，有的卷积核可以提取出图片中的某种颜色等。这是一个具体的例子：
                    </p>
                    <img src="/images/blogs/2018/cnn_filter_ops.gif" width="70%" style="margin: 0 15%">
                    <h4>$\star$ 卷积核的尺寸</h4>
                    <p>
                        注意到，我们上边一直都是以黑白图像为例来说明的，其对应的卷积核都是二维的。而对于彩色图像，这个图像的数据往往是一个三维的数组(每个像素对应有RGB三个颜色通道)：
                    </p>
                    <img src="/images/blogs/2018/color_img.png" width="70%" style="margin: 0 15%">
                    <p>
                        这个时候对应的卷积核就也是三维的了，对于更高维的数据，卷积核的维度也相应地改变。
                    </p>
                    <h4>$\star$ 特征图的尺寸</h4>
                    <p>
                        如果足够细心的话，你应该会发现元素图像在经过卷积之后得到的特征图的尺寸会有所不同。确实是这样，一个特征图的尺寸与以下几个因素有关：
                    </p>
                    <ul class="reference">
                        <li>输入的图片的大小(input size)</li>
                        <li>卷积核的大小(filter size)</li>
                        <li>作卷积时的步长(stride)</li>
                        <li>填充大大小(padding )</li>
                    </ul>
                    <p>
                        为了便于说明，这里设图片的大小为$i$，卷积核的大小为$k$，步长为$s$，填充的大小为$p$，特征图的尺寸为$o$。
                        那么可以得到
                        $$ o = \frac{i + 2p - k + 1}{s}$$
                        下面是一个$p = 1, i = 5, k = 3, s = 1$的例子：
                    </p>
                    <img src="/images/blogs/2018/feature_map_size.png" width="100%">

                    <h4>$\star$ 进行卷积的路径</h4>
                    <p>
                        CNN不仅适用于图像识别，它在语音识别等领域也有很有效的效果。在不同的应用场景，卷积操作的路径也是不一样的：在图像识别中，我们前面已经看到他会按照从左到右，再从上到下的顺序“扫描整张图片”；但是在语音识别时，它只用按照下面的方式在采集到的音频数据上从上到下进行一次“扫描”就可以了，这里不进行详细解读。
                    </p>
                    <img src="/images/blogs/2018/cnn_voice.png" width="70%" style="margin: 0 15%">
                </div>

                <div class="blog_content">
                    <h3>池化操作</h3>
                    <h4>$\star$ 基本操作</h4>
                    <p>
                        池化操作(pooling)的本质就是采样，可以采取的操作有：最大化、平均化、加和等。最常用并且被证明效果很好的池化操作为最大池化。
                        <br><br>
                        所谓最大池化就是，我们定义一个空间临域(比如一个2X2的窗口)，并从窗口内的特征图中取出最大的元素。
                    </p>
                    <img src="/images/blogs/2018/cnn_maxpooling.png" width="70%" style="margin: 0 15%">
                    <h4>$\star$ 池化的意义</h4>
                    <p>
                        首先，经过池化操作之后，可以有效地减少参数但又能保留主要特征，还有助于改善结果(不容易过拟合)，以最大池化为例，池化之后可以使得到该特征图的卷积核偏好的那个特征得到保留与增强(因为值大)，而其他的一些“干扰”则被削弱。
                        <br><br>
                        其次，可以发挥特征图的“不变性”(invariance)，特征的平移，旋转，尺度变化对网络的干扰都会在一定程度上得到缓解。
                    </p>
                </div>

                <div class="blog_content">
                    <h3>LeNet-5</h3>
                    <p>
                        经过上面的一大堆啰嗦，我们应该已经对CNN里边的卷积和池化操作有了一定的了解，下面就开始进入正题吧——LeNet-5。
                    </p>
                </div>

                <div class="blog_content">
                    <h4>$\star$ LeNet-5的结构</h4>
                    <p>
                        首先，放出我们很熟悉那张LeNet-5的结构示意图：
                    </p>
                    <img src="/images/blogs/2018/cnn_lenet5.png" width="100%">
                    <p>
                        不算上输入层的话，LeNet-5是一个7层的神经网络，从前到后分别是：
                    </p>
                    <div class="timeline">
                    
                        <h4 class="timetag">#001</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-1,
                                            .cls-4 {
                                                fill: none;
                                            }
                    
                                            .cls-1 {
                                                stroke: #f23030;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-2 {
                                                fill: #f23030;
                                            }
                    
                                            .cls-3 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-1" transform="translate(1056 251)">
                                            <circle class="cls-3" cx="25" cy="25" r="25" />
                                            <circle class="cls-4" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-2" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>C1层(卷积层)</h4>
                            <p class="timeintro top-to-bottom"><br />
                                C1层有6个28x28的特征图组成，每个特征图中的任一个元素与该层的输入中一个5x5的区域相连接。如图所示：
                                <br><br>
                                <img src="/images/blogs/2018/lenet_c1.png" width="80%" style="margin: 0 10%">
                                <br><br>
                                C1层一共有$(5\times 5+1) \times 6 = 156$个可训练的参数，而且一共有$(5 \times 5 + 1) \times 28 \times 28 \times 6 = 122,304$个连接。
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>
                    
                    <div class="timeline">
                    
                        <h4 class="timetag">#002</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-11,
                                            .cls-14 {
                                                fill: none;
                                            }
                    
                                            .cls-11 {
                                                stroke: #ffb134;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-12 {
                                                fill: #ffb134;
                                            }
                    
                                            .cls-13 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-11" transform="translate(1056 251)">
                                            <circle class="cls-13" cx="25" cy="25" r="25" />
                                            <circle class="cls-14" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-12" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>S2层(池化层)</h4>
                            <p class="timeintro top-to-bottom1"><br />
                                S2层是一个池化层，由6个14x14的特征图组成，每一个特征图中元素都与C1层中对应的特征图中一个2x2的相邻区域相连。这里的池化操作为：将4个输入相加，乘上一个可训练的系数，加上一个可训练的偏置，最后经过一个$Sigmoid$函数。
                                <br><br>
                                <img src="/images/blogs/2018/lenet_s2.png" width="80%" style="margin: 0 10%">
                                <br><br>
                                S2层一共有$(1 + 1) \times 6 = 12$个可训练的参数，而且一共有$(2 \times 2 + 1) \times 14 \times 14 \times 6 = 5,880$个连接。
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>
                    
                    <div class="timeline">
                    
                        <h4 class="timetag">#003</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-21,
                                            .cls-24 {
                                                fill: none;
                                            }
                    
                                            .cls-21 {
                                                stroke: #FAEE5D;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-22 {
                                                fill: #FAEE5D;
                                            }
                    
                                            .cls-23 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-21" transform="translate(1056 251)">
                                            <circle class="cls-23" cx="25" cy="25" r="25" />
                                            <circle class="cls-24" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-22" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>C3层(卷积层)</h4>
                            <p class="timeintro top-to-bottom2"><br>
                                C3层由16个10x10的特征图组成，与C1的最大区别是，这里每个特征图中的元素会与S2层中若干个特征图中处于相同位置的5x5的区域相连，如图所示：
                                <br><br>
                                <img src="/images/blogs/2018/lenet_c3s2" width="50%" style="margin: 0 25%">
                                <br><br>
                                而其具体的连接方案如下表所示：
                                <br><br>
                                <img src="/images/blogs/2018/lenet_c3.png" width="80%" style="margin: 0 10%">
                                <br><br>
                                具体来说，C3层中首先会将得到的对应的卷积结果相加，然后再进行类似C1层的加偏置的操作，从而得到一个元素。按照上表中的规则连接，C3层一共有$6 \times (3 \times 25 + 1) + 9 \times (4 \times 25 + 1) + 1 \times (6 \times 25 + 1) = 1,516$个可训练的参数，一共有$151,600$个连接。
                                <br><br>
                                ⚠️另外，值得说的一点是，为什么要采用上面的连接方案，而不是“全”连接？首先，不完全的连接可以减少参数和连接数；其次，我们知道每个特征图对应的就是卷积核从输入中提取出的不同的特征，采取这种不对称的连接，可以使本层的特征图对应的不同的更高级的特征。
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>
                    
                    <div class="timeline">
                    
                        <h4 class="timetag">#004</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-31,
                                            .cls-34 {
                                                fill: none;
                                            }
                    
                                            .cls-31 {
                                                stroke: #25DD73;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-32 {
                                                fill: #25DD73;
                                            }
                    
                                            .cls-33 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-31" transform="translate(1056 251)">
                                            <circle class="cls-33" cx="25" cy="25" r="25" />
                                            <circle class="cls-34" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-32" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>S4层(池化层)</h4>
                            <p class="timeintro top-to-bottom3"><br>
                                S4层是一个池化层，他由16个5x5的特征图构成，其操作和S2层相同。其共有$32$和可训练的参数和$2000$个连接。
                                <br><br><br> 
                            </p>
                        </article>
                    
                    </div>
                    
                    <div class="timeline">
                    
                        <h4 class="timetag">#005</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-41,
                                            .cls-44 {
                                                fill: none;
                                            }
                    
                                            .cls-41 {
                                                stroke: #30A4F8;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-42 {
                                                fill: #30A4F8;
                                            }
                    
                                            .cls-43 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-41" transform="translate(1056 251)">
                                            <circle class="cls-43" cx="25" cy="25" r="25" />
                                            <circle class="cls-44" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-42" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>C5层(卷积层)</h4>
                            <p class="timeintro top-to-bottom4"><br>
                                C5是一个类似C3的卷积层，由120个1x1的特征图组成。但是，与C3层不同的是，这里的连接是一种“全”连接，即每个特征图中的元素与S4层中每个特征图都连接。
                                <br><br>
                                S2层一共有$120 \times(5\times 5 \times 16 + 1 ) = 48,120$个可训练的参数。
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>
                    
                    <div class="timeline">
                    
                        <h4 class="timetag">#006</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-51,
                                            .cls-54 {
                                                fill: none;
                                            }
                    
                                            .cls-51 {
                                                stroke: #08FDE1;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-52 {
                                                fill: #08FDE1;
                                            }
                    
                                            .cls-53 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-51" transform="translate(1056 251)">
                                            <circle class="cls-53" cx="25" cy="25" r="25" />
                                            <circle class="cls-54" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-52" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>F6层(全连接层)</h4>
                            <p class="timeintro top-to-bottom5"><br>
                                F6就是一个简单的全连接层，它由84个神经元构成，每个神经元将C5层中的特征图的值乘上权重相加，加上偏置再经过$Sigmoid$函数。
                                <br><br>
                                F6层共有$84 \times (120 + 1) = 10,164$个可训练的参数。
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>
                    
                    <div class="timeline">
                    
                        <h4 class="timetag">#007</h4>
                        <article>
                    
                            <h4><svg class="timecircle" viewBox="0 0 50 50">
                                    <defs>
                                        <style>
                                            .cls-61,
                                            .cls-64 {
                                                fill: none;
                                            }
                    
                                            .cls-61 {
                                                stroke: #6630F8;
                                                stroke-width: 5px;
                                            }
                    
                                            .cls-62 {
                                                fill: #6630F8;
                                            }
                    
                                            .cls-63 {
                                                stroke: none;
                                            }
                                        </style>
                                    </defs>
                                    <g id="Group_1" data-name="Group 1" transform="translate(-1056 -251)">
                                        <g id="Ellipse_1" data-name="Ellipse 1" class="cls-61" transform="translate(1056 251)">
                                            <circle class="cls-63" cx="25" cy="25" r="25" />
                                            <circle class="cls-64" cx="25" cy="25" r="22.5" />
                                        </g>
                                        <circle id="Ellipse_2" data-name="Ellipse 2" class="cls-62" cx="12" cy="12" r="12" transform="translate(1069 264)" />
                                    </g>
                                </svg>输出层</h4>
                            <p class="timeintro top-to-bottom6end"><br />
                                该层也是全连接层，共有10个节点，分别代表数字0到9。如果节点i的值为0，则网络识别的结果是数字i。<br><br>
                                ⚠️1：这一层采用的是(高斯)径向基函数核(Radial basis function kernel, RBF)的连接方式。假设其输入为$\vec{x}$，则RBF输出o是：<br><br>
                                $$ o = || \vec{x} - \vec{w} ||^2 $$
                                <br>
                                ⚠️2：每个RBF中的$\vec{w}$的值由其对应的i的编码是人为确定的，且被设计成7X12的标准格式(这下子终于知道为什么上一层是84个了)。RBF输出越接近于0，即输入$\vec{w}$越接近于i的编码。
                                <br><br><br>
                            </p>
                        </article>
                    
                    </div>
                </div>

                <div class="blog_content">
                    <h4>$\star$ 整体效果</h4>
                    <p>
                        经过上面的啰嗦，相信大家对LeNet-5的细节已经略有掌握了。下面放一张预测的效果图：
                        <br><br>
                        <img src="/images/blogs/2018/lenet_exam" width="80%" style="margin: 0 10%">
                    </p>
                </div>

                <div class="blog_content">
                    <h3>如何训练LeNet-5</h3>
                    <p>
                    </p>
                </div>
                
                <hr>

                <div class="blog_content">
                    <h3>代码实现</h3>
                    这里我们来实现LeNet-5
                    <h4>网络设计</h4>
                    <h3>Keras实现</h3>
                    <pre>
                        <code class="python">
from keras.model import S
import tensroflow
                        </code>
                    </pre>
                </div>

                <div class="blog_content">
                    <h3>原论文的叙述</h3>
                </div>

                <div class="blog_content paperReference">
                    <blockquote>
                        <img src="/images/blogs/2018/cnn_lenet5.png" width="100%">
                        <h4><i>B. LeNet-5</i></h4>
                        <p style="line-height: 1.5">
                            This section describes in more details the architecture of LeNet-5, the Convolutional Neural Network used in the experimennts.
                            LeNet-5 comprises 7 layers, not counting the input, all of which contain trainable parameters (weights).
                            The input is a 32x32 piexl image.
                            This is significantly larger than the largest character in the database (at most 20x20 piexl centered in a 28x28 field).
                            The reason is that it is desirable that potential distinctive features such as stroke end-point or cornor can appear <i>in the center of </i> the receptice field of the highest-level feature detecture.
                            In LetNet-5 the set of centers of the receptive fields of the last convolutional layer (C3, see blow) from 20x20 area in the center of the 32x32 input.
                            The values of the input piexl are normalized so that the background level (white) corresponds to a value of -0.1 and the foreground (black) corresponds to 1.175.
                            This makes the mean input roughly 0, and the variance roughly 1 which accelerate learning.
                            <br><br>
                            In the following, convolutional layers are labeled Cx, sub-sampling layers are labeled Sx, and fully-connected layers are lebeled Fx, where x is the layer index.
                            <br><br>
                            Layer C1 is a convolutional layer with 6 feature maps. Each unit in each feature map is connected to a 5x5 neighborhood in the input.
                            The size of the feature maps is 28x28 which prevents connection from the input from falling off the boundary.
                            C1 contains 156 trainable parameters, and 122,304 connections.
                            <br><br>
                            Layer S2 is a sub-sampling layer withh 6 feature maps of size 14x14.
                            Each unit in each feature map is connected to a 2x2 neighborhood in the corresponding feature map in C1.
                            The four inputs to a unit in S2 are added, then multiplied by a trainable coefficient, and added to a trainable bias.
                            The result is passed through a sigmoidal fucntion.
                            The 2x2 receptive fields a non-overlapping, therefore feature maps in S2 have half the number of rows and columns as feature maps in C1.
                            Layer S2 has 12 trainable parameters and 5,880 connections.
                            <br><br>
                            Layer C3 is a convolutional layer with 16 feature maps. Each unit in each feature map is connected to several 5x5 neighborhoods at identical locations in a subset of S2's feature maps.
                            Table I shows the set of S2 feature maps combined by each C3 feature maps. Why not connect every S2 feature map to every C3 feature map? The reason is twofold. 
                            First, a non-complete connection scheme keeps the number of connections within reasonale bounds.
                            More importantly, is forces a break of symmetry in the network.
                            Diffferent feature maps are forced to extract different (hopefully complementary) features because they get different sets of inputs.
                            The rationale behind the connection scheme in talbe I is the following. The first six C3 feature maps take input from every contiguous subsets of three feature maps in S2.
                            The next six take input from every contiguous subsets of four.
                            The next three take input from some discontinuous subsets of four. 
                            Finally the last one takes input from all S2 feature maps. Layer C3 has 1,516 trainable parameters and 151,600 connections.
                            <br><br>
                            Layer S4 is a sub-sampling layer with 16 feature maps of size 5x5. Each unit in each feature map is connected to a 2x2 neighborhood in the corresponding fature map in C3, in a similar way as C1 and C2. Layer S4 has 32 trainable parameters and 2,000 connections.  
                            <br><br>
                            Layer C5 is a convolutional layer with 120 feature maps. Each unit is connected to a 5x5 neighborhood on all 16 of S4's feature maps.
                            Here, because the size of S4 is also 5x5, the size of C5's feature maps is 1x1: this amounts to a full connection between S4 and C5. 
                            C5 is labeled as a convolutional layer, instead of a fully-connected layer, because if LeNet-5 input were made bigger with wvwrything else kept constant, the feature map dimension would be larger than 1x1.
                            This process of dynamically increasing the size of a convolutional network is described in the section Section VII.
                            Layer C5 has 48,120 trainable connections.
                            <br><br>  
                            Layer F6, contains 84 unit (the reason for this number comes from the design of output layer, explained below) and is fully connected to C5. It has 10,164 trainable parameters.
                            <br><br>
                            As in classical neural networks, units in layers up to F6 computer a dot product between their innput vector annd their weight vector, to which a bias is added. This weighted sum, denoted $a_i$ for unit $i$, is then passed through a sigmoid squashing function to produce the state of unit $i$, denoted by $x_i$:
                            $$ x_i = f(a_i) $$
                            Then squashing function is scaled hyperbolic tangent:
                            $$ f(a) = A tanh(Sa) $$
                            Where $A$ is the amplitude of the function and S determines its slope at origin.
                            The funtion $f$ is odd, with horizontal asymptotes as $+A$ and $-A$. The constant $A$ is chosen to be 1.7159. The rationale for this choice of a squashing function is given in Appendix A.
                            <br><br>
                            Finally, the output layer layer is composed of Euclidean Radial Basis Function units (RBF), one for each class, with 84 inputs each.
                            The outputs of each RBF unit $y_i$ is computed as following:
                            $$ y_i = \sum_{j}{(x_j - w_{ij})^2}. $$
                            In other words, each output RBF unit computes the Euclidean diatance between its input vector and its parameter vector. The further away is the input vector and its parameter vector.
                            The further away is the input from the parameter vector, the larger is the RBF output. The output of a particular RBF can be interpreted as a penalty term measuring the fit between the input pattern and a model of the class associated with the RBF. 
                            In probabilistic terms, the RBF output can be interpreted as the unnormalized negative log-likelihood of a Gaussian distribution in the space of cinfigurations of layer F6. 
                            Given an input pattern the loss function should be designed so as to get thhe configuration of F6 as close as possible to the pattern's desired class.
                            The parameter vectors of these units were chosen by hand and kept fixed (at least initially). 
                            The components of those parameters vectors were set to -1 or +1. While they could have been chosen at random with equal probabilities for -1 and  +1, or even chosen to form an error correcting code as suggested by [47], they were instead designed to represent a stylized image of the corresponding character class drawn on a 7x12 bitmap (hense the number 84). 
                            Such a representation is not particularly useful for recognizing isolated digits, but it is quite useful for recognizing strings of characters taken from the full printable ASCII set.
                            The rationale is that characters that are similar, and therefore confusale, such as uppercase O, lowercase O, and zero, or lowercase l, digit 1, square brackets, and uppercase I, will have similar output codes.
                            This is particularly useful if the system is combined with a linguistic post-processor that can correct such sonfusions.
                            Because the codes for confusable classes are similar, the output of the corresponding RBFs for anambiguous character will be similar, and the post-processor will be able to pick the appropriate interpretation. Figure 3 gives the output codesd for the full ASCII set.
                            <br><br>
                            Another reason for using such distributed codes, rather than the more common "1 of N" code (also called place code, or grand-mother cell code) for the output is that non distributed codes tend to behave badly when the number of classes id larger than a few dozens.
                            The reason is that output units in a non-distributed code must be off most of the time. This is quite difficult to achieve with sigmoid units. 
                            Yet another reason is that the classifiers are often used to not only recognize character, but also to reject non-character. RBFs with distributed codes are more appropriate for that purpose because unlike sigmoids, they are activated within a well circumscribed region of their input space that non-typical pattern are more likely to fall outside of.
                            <br><br>
                            The parameter vector of the RBFs play the role of target vectors for layer F6. 
                            It is worth pointing out that the components of those vectors are -1 or +1, which is well within the range of the rigmoid of F6, and therefore prevents those sigmoids from getting saturated. In fact, +1 and -1 are the points of maximum curvature of the sigmoids. This forces the F6 units of maximum... 
                         </p>

                        <br><br>
                        <i style="color: black">Cite from "Gradient-Based Learning Applied to Document Recognition"</i>
                        <br>
                    </blockquote>
                </div>



                <div class="blog_content">
                    <style>
                        #bloglink {
                            text-align: left;
                        }
                    </style>
                    <p>上一篇：无</p>
                    <p>下一篇：<a href="/blogs/2018/ai/NN/cnn.html">CNN简史</a></p>
                </div>

                <div class="blog_content">
                    <h3>参考：</h3>
                    <ul class="reference">
                        <li><i><a href="http://ufldl.stanford.edu/wiki/index.php/%E6%B1%A0%E5%8C%96">池化</a></i></li>
                        <li><i><a href="http://www.hackcv.com/index.php/archives/104/?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io">什么是卷积神经网络？为什么它们很重要？</a></i></li>
                        <li><i><a href="https://blog.csdn.net/d5224/article/details/68928083">卷积神经网络Lenet-5详解</a></i></li>
                        <li><i><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional neural network - wikipedia</a></i></li>
                        <li><i><a href="https://blog.csdn.net/xzy_thu/article/details/69808817">李宏毅机器学习课程笔记4：CNN、Why Deep、Semi-supervised</a></i></li>
                        <li><i><a href="https://arxiv.org/pdf/1603.07285.pdf">A guide to convolution arithmetic for deep learning</a></i></li>
                        <li><i><a href="http://www.jeyzhang.com/cnn-learning-notes-1.html">卷积神经网络(CNN)学习笔记1：基础入门</a></i></li>
                        <li><i><a href="https://blog.csdn.net/sinat_24143931/article/details/78958931">LeNet-5网络模型详解</a></i></li>
                    </ul>
                </div>
            </section>
        </main>
    </div>

    <div id="contact" class="content">
        <p id="welcome">Welcome to join me to find and create bueautiful stuffs!</p>
        <p id="cvia">Contact me via:</p>
        <div id="mi_logos">
            <img src="/images/facebook.svg" class="logos link">
            <img src="/images/instagram.svg" class="logos link">
            <img src="/images/twitter.svg" class="logos link">
            <img src="/images/wechat.svg" class="logos link">
            <img src="/images/weibo.svg" class="logos link">
        </div>
        <hr />
        <p id="copyright">A project by Charley Chai</p>
    </div>
    <script src="/scripts/temp.js"></script>
    <script src="/scripts/blogs.js"></script>
    <link href="/styles/monokai.css" rel="stylesheet">
    <script src="/scripts/src/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
</body>

</html>